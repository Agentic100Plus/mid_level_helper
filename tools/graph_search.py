"""ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ë„êµ¬ (LangChain Tool)."""

from langchain.tools import tool

from utils.graph_queries import (
    get_related_keywords,
    search_documents_by_keywords,
)


@tool
def graph_keyword_search(keywords: str) -> str:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê·¸ë˜í”„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ê°œë°œì ì‚¬ë¡€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” FalkorDB ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì™€ ì—°ê²°ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œ ê°„ì˜ ê´€ê³„(ê³µë™ ì¶œí˜„)ë¥¼ í™œìš©í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œë“¤ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: "ì„±ì¥í†µ, ì¬íƒê·¼ë¬´, ë™ê¸°ë¶€ì—¬")

    Returns:
        ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ (ì œëª©, ì¹´í…Œê³ ë¦¬, ë¬¸ì œ ìš”ì•½, ë§¤ì¹­ í‚¤ì›Œë“œ)
    """
    # í‚¤ì›Œë“œ íŒŒì‹±
    keyword_list = [kw.strip() for kw in keywords.split(",") if kw.strip()]

    if not keyword_list:
        return "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        # ê·¸ë˜í”„ ê²€ìƒ‰ ì‹¤í–‰
        documents = search_documents_by_keywords(keyword_list, limit=5)

        if not documents:
            return f"í‚¤ì›Œë“œ '{keywords}'ì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§¤íŒ…
        result_lines = [f"ğŸ” í‚¤ì›Œë“œ '{keywords}' ê²€ìƒ‰ ê²°ê³¼: {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬\n"]

        for i, doc in enumerate(documents, 1):
            matched_kw = ", ".join(doc["matched_keywords"])
            result_lines.append(f"[{i}] {doc['title']}")
            result_lines.append(f"    ì¹´í…Œê³ ë¦¬: {doc['category']}")
            result_lines.append(f"    ë§¤ì¹­ í‚¤ì›Œë“œ: {matched_kw}")
            result_lines.append(f"    ê´€ë ¨ë„: {doc['relevance_score']}ì ")
            result_lines.append(f"    ë¬¸ì œ: {doc['problem_summary'][:100]}...")
            result_lines.append("")

        return "\n".join(result_lines)

    except Exception as e:
        return f"âŒ ê·¸ë˜í”„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
def graph_related_keywords(keyword: str) -> str:
    """íŠ¹ì • í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ë‹¤ë¥¸ í‚¤ì›Œë“œë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ê°„ì˜ ê³µë™ ì¶œí˜„ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬
    ì—°ê´€ëœ í‚¤ì›Œë“œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ í™•ì¥í•˜ê±°ë‚˜ êµ¬ì²´í™”í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.

    Args:
        keyword: ê¸°ì¤€ í‚¤ì›Œë“œ (ì˜ˆ: "ì„±ì¥í†µ")

    Returns:
        ê´€ë ¨ í‚¤ì›Œë“œ ëª©ë¡ (ê³µë™ ì¶œí˜„ ë¹ˆë„ ìˆœ)
    """
    if not keyword:
        return "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

    try:
        # ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        related = get_related_keywords(keyword, limit=10)

        if not related:
            return f"í‚¤ì›Œë“œ '{keyword}'ì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§¤íŒ…
        result_lines = [f"ğŸ”— '{keyword}'ì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œ:\n"]

        for i, kw in enumerate(related, 1):
            result_lines.append(f"{i}. {kw['name']}")
            result_lines.append(f"   - ê³µë™ ì¶œí˜„: {kw['weight']}íšŒ")
            result_lines.append(f"   - ê´€ë ¨ ë¬¸ì„œ: {kw['documents_count']}ê°œ")

        return "\n".join(result_lines)

    except Exception as e:
        return f"âŒ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ë„êµ¬ ëª©ë¡ (export)
graph_tools = [graph_keyword_search, graph_related_keywords]


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§ª ê·¸ë˜í”„ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸\n")

    # 1. í‚¤ì›Œë“œ ê²€ìƒ‰
    print("=" * 60)
    print("í…ŒìŠ¤íŠ¸ 1: í‚¤ì›Œë“œ ê²€ìƒ‰")
    print("=" * 60)
    result1 = graph_keyword_search.invoke({"keywords": "ì„±ì¥í†µ, ì¬íƒê·¼ë¬´"})
    print(result1)

    # 2. ê´€ë ¨ í‚¤ì›Œë“œ
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 2: ê´€ë ¨ í‚¤ì›Œë“œ")
    print("=" * 60)
    result2 = graph_related_keywords.invoke({"keyword": "ì„±ì¥í†µ"})
    print(result2)
