"""Pinecone ë²¡í„° ë°ì´í„°ë¥¼ FalkorDB ê·¸ë˜í”„ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜."""

import os
import sys
from collections import Counter, defaultdict
from typing import Any

from dotenv import load_dotenv
from pinecone import Pinecone
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from utils.data_loader import extract_keywords_list
from utils.graph_db import (
    clear_graph,
    create_graph_schema,
    get_graph,
    print_graph_stats,
)

load_dotenv()

# ì„¤ì •
NAMESPACE = "20251029_crawling"
GRAPH_NAME = "mid_level_helper"
BATCH_SIZE = 100

print("\n" + "=" * 60)
print("ğŸš€ FalkorDB ê·¸ë˜í”„ êµ¬ì¶• ì‹œì‘")
print("=" * 60)

# ============================================
# 1. Pinecone ì—°ê²°
# ============================================
print("\nğŸ“¦ Pinecone ì—°ê²° ì¤‘...")
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index_name = os.getenv("PINECONE_INDEX_NAME", "mid-level-helper")
index = pc.Index(index_name)

# ì¸ë±ìŠ¤ í†µê³„ í™•ì¸
stats = index.describe_index_stats()
print(f"âœ… Pinecone ì¸ë±ìŠ¤: {index_name}")
print(f"   - ì´ ë²¡í„° ìˆ˜: {stats.total_vector_count:,}")
print(f"   - ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {NAMESPACE}")

# ============================================
# 2. FalkorDB ì´ˆê¸°í™”
# ============================================
print("\nğŸ”¨ FalkorDB ì´ˆê¸°í™” ì¤‘...")
graph = get_graph(GRAPH_NAME)

# ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒì )
print("âš ï¸  ê¸°ì¡´ ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ", end="")
response = input().strip().lower()
if response == "y":
    clear_graph(GRAPH_NAME)
    print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
else:
    print("â­ï¸  ê¸°ì¡´ ë°ì´í„° ìœ ì§€")

# ìŠ¤í‚¤ë§ˆ ìƒì„±
create_graph_schema(GRAPH_NAME)

# ============================================
# 3. Pineconeì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
# ============================================
print("\nğŸ“¥ Pinecone ë°ì´í„° ê°€ì ¸ì˜¤ê¸°...")


def fetch_all_vectors_from_pinecone(
    index: Any, namespace: str, batch_size: int = 100
) -> list[dict[str, Any]]:
    """Pineconeì—ì„œ ëª¨ë“  ë²¡í„° ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°.

    Args:
        index: Pinecone ì¸ë±ìŠ¤
        namespace: ë„¤ì„ìŠ¤í˜ì´ìŠ¤
        batch_size: ë°°ì¹˜ í¬ê¸°

    Returns:
        ë²¡í„° ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    all_vectors = []

    # Pineconeì˜ list ë©”ì„œë“œë¡œ ëª¨ë“  ID ê°€ì ¸ì˜¤ê¸°
    try:
        # Query ë°©ì‹ìœ¼ë¡œ ìƒ˜í”Œë§ (Pineconeì˜ ì œí•œìœ¼ë¡œ ì¸í•´)
        # ë”ë¯¸ ë²¡í„°ë¡œ ì¿¼ë¦¬í•˜ì—¬ ëª¨ë“  ë°ì´í„° ì ‘ê·¼
        print("   ë²¡í„° ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...")

        # statsì—ì„œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ë²¡í„° ìˆ˜ í™•ì¸
        namespace_stats = stats.namespaces.get(namespace, {})
        total_count = namespace_stats.vector_count if hasattr(namespace_stats, "vector_count") else 0

        print(f"   - ëŒ€ìƒ ë²¡í„° ìˆ˜: {total_count:,}ê°œ")

        # ë°©ë²• 1: ë”ë¯¸ ì¿¼ë¦¬ë¡œ top_k ë°©ì‹ (ì œí•œì )
        # ë°©ë²• 2: list_paginatedë¥¼ ì‚¬ìš©í•œ ID ê°€ì ¸ì˜¤ê¸°
        results = index.list_paginated(namespace=namespace, limit=10000)

        vector_ids = [v.id for v in results.vectors]
        print(f"   - ê°€ì ¸ì˜¨ ID ìˆ˜: {len(vector_ids):,}ê°œ")

        # fetchë¡œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        for i in tqdm(range(0, len(vector_ids), batch_size), desc="ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"):
            batch_ids = vector_ids[i : i + batch_size]
            fetch_result = index.fetch(ids=batch_ids, namespace=namespace)

            for vec_id, vector_data in fetch_result.vectors.items():
                metadata = vector_data.metadata
                metadata["id"] = vec_id
                all_vectors.append(metadata)

    except Exception as e:
        print(f"âŒ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        print("âš ï¸  ëŒ€ì•ˆ: CSV ë°ì´í„°ì—ì„œ ì§ì ‘ ë¡œë“œ")
        return []

    return all_vectors


vectors = fetch_all_vectors_from_pinecone(index, NAMESPACE, BATCH_SIZE)
print(f"âœ… ë²¡í„° ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ: {len(vectors):,}ê°œ")

# CSV ëŒ€ì²´ ë°©ë²•ì´ í•„ìš”í•œ ê²½ìš°
if len(vectors) == 0:
    print("\nâš ï¸  Pineconeì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   CSV íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œí•©ë‹ˆë‹¤...")

    from utils.data_loader import load_csv_data, prepare_documents_for_vectorstore

    df = load_csv_data()
    _, metadatas = prepare_documents_for_vectorstore(df)
    vectors = metadatas
    print(f"âœ… CSVì—ì„œ ë¡œë“œ ì™„ë£Œ: {len(vectors):,}ê°œ")

# ============================================
# 4. ê·¸ë˜í”„ êµ¬ì¶•
# ============================================
print("\nğŸ”¨ ê·¸ë˜í”„ êµ¬ì¶• ì¤‘...")

# ì¹´í…Œê³ ë¦¬ ë…¸ë“œ ìƒì„±
categories = set()
for vec in vectors:
    category = vec.get("category", "ê¸°íƒ€")
    if category:
        categories.add(category)

print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ ë…¸ë“œ ìƒì„±: {len(categories)}ê°œ")
for category in tqdm(categories, desc="ì¹´í…Œê³ ë¦¬"):
    query = f"""
    MERGE (c:Category {{name: $name}})
    """
    graph.query(query, {"name": category})

# í‚¤ì›Œë“œ ë…¸ë“œ ë° ë¬¸ì„œ ë…¸ë“œ ìƒì„±
print(f"\nğŸ“„ ë¬¸ì„œ ë° í‚¤ì›Œë“œ ë…¸ë“œ ìƒì„±: {len(vectors)}ê°œ")

keyword_counter = Counter()
keyword_cooccurrence: dict[str, Counter] = defaultdict(Counter)

for vec in tqdm(vectors, desc="ë¬¸ì„œ ì²˜ë¦¬"):
    doc_id = vec.get("id", "")
    title = vec.get("title", "")
    source = vec.get("source", "")
    problem_summary = vec.get("problem_summary", "")
    category = vec.get("category", "ê¸°íƒ€")
    keywords_str = vec.get("keywords", "")

    # ë¬¸ì„œ ë…¸ë“œ ìƒì„±
    doc_query = """
    MERGE (d:Document {id: $id})
    SET d.title = $title,
        d.source = $source,
        d.problem_summary = $problem_summary,
        d.category = $category
    """
    graph.query(
        doc_query,
        {
            "id": doc_id,
            "title": title,
            "source": source,
            "problem_summary": problem_summary,
            "category": category,
        },
    )

    # ì¹´í…Œê³ ë¦¬ ê´€ê³„ ìƒì„±
    category_rel_query = """
    MATCH (d:Document {id: $doc_id})
    MATCH (c:Category {name: $category})
    MERGE (d)-[:BELONGS_TO]->(c)
    """
    graph.query(category_rel_query, {"doc_id": doc_id, "category": category})

    # í‚¤ì›Œë“œ ì²˜ë¦¬
    keywords = extract_keywords_list(keywords_str)

    for keyword in keywords:
        if not keyword:
            continue

        keyword_counter[keyword] += 1

        # í‚¤ì›Œë“œ ë…¸ë“œ ìƒì„±
        keyword_query = """
        MERGE (k:Keyword {name: $name})
        """
        graph.query(keyword_query, {"name": keyword})

        # ë¬¸ì„œ-í‚¤ì›Œë“œ ê´€ê³„ ìƒì„±
        doc_keyword_query = """
        MATCH (d:Document {id: $doc_id})
        MATCH (k:Keyword {name: $keyword})
        MERGE (d)-[:HAS_KEYWORD]->(k)
        """
        graph.query(doc_keyword_query, {"doc_id": doc_id, "keyword": keyword})

    # í‚¤ì›Œë“œ ê³µë™ ì¶œí˜„ ì¶”ì 
    for i, kw1 in enumerate(keywords):
        for kw2 in keywords[i + 1 :]:
            if kw1 and kw2 and kw1 != kw2:
                keyword_cooccurrence[kw1][kw2] += 1
                keyword_cooccurrence[kw2][kw1] += 1

# í‚¤ì›Œë“œ ê³µë™ ì¶œí˜„ ê´€ê³„ ìƒì„±
print(f"\nğŸ”— í‚¤ì›Œë“œ ê³µë™ ì¶œí˜„ ê´€ê³„ ìƒì„±...")
total_cooccurrences = sum(len(v) for v in keyword_cooccurrence.values()) // 2

for kw1, cooccurs in tqdm(
    keyword_cooccurrence.items(), desc="ê³µë™ ì¶œí˜„", total=len(keyword_cooccurrence)
):
    for kw2, weight in cooccurs.items():
        if kw1 < kw2:  # ì¤‘ë³µ ë°©ì§€ (ì–‘ë°©í–¥ ì¤‘ í•œ ë²ˆë§Œ)
            cooccur_query = """
            MATCH (k1:Keyword {name: $kw1})
            MATCH (k2:Keyword {name: $kw2})
            MERGE (k1)-[r:CO_OCCURS_WITH]-(k2)
            SET r.weight = $weight
            """
            graph.query(cooccur_query, {"kw1": kw1, "kw2": kw2, "weight": weight})

# ============================================
# 5. ê²°ê³¼ í™•ì¸
# ============================================
print("\n" + "=" * 60)
print("âœ… ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ!")
print("=" * 60)

print_graph_stats(GRAPH_NAME)

# ìƒìœ„ í‚¤ì›Œë“œ ì¶œë ¥
print("\nğŸ“Š ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ:")
for keyword, count in keyword_counter.most_common(10):
    print(f"   {count:4d}íšŒ - {keyword}")

print("\n" + "=" * 60)
print("ğŸ‰ FalkorDB ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ!")
print("=" * 60)
